# 
# å®éªŒä¸€ çº¿æ€§å›å½’ï¼ˆé»‘ä½“ä¸‰å·ï¼‰
## ä¸€ã€å®éªŒç›®çš„
1.æ­å»ºæœºå™¨å­¦ä¹ å¼€å‘å¹³å°ã€‚
2.æŒæ¡çº¿æ€§å›å½’åˆ†æçš„åŸºæœ¬æ€æƒ³å’ŒåŸºæœ¬æ–¹æ³•ï¼ˆéš¾ç‚¹ï¼‰ã€‚
3.æŒæ¡æœ€å°äºŒä¹˜æ³•åŸç†åŠå®ç°ï¼ˆé‡ç‚¹ï¼‰ã€‚
## äºŒã€å®éªŒåŸç†åŠè¯´æ˜
çº¿æ€§å›å½’æ˜¯åœ¨å·²æœ‰æ•°æ®é›†ä¸Šé€šè¿‡æ„å»ºä¸€ä¸ªçº¿æ€§çš„æ¨¡å‹æ¥æ‹Ÿåˆè¯¥æ•°æ®é›†ç‰¹å¾å‘é‡çš„å„ä¸ªåˆ†é‡ä¹‹é—´çš„å…³ç³»ï¼Œå¯¹äºéœ€è¦é¢„æµ‹ç»“æœçš„æ–°æ•°æ®ï¼Œæˆ‘ä»¬åˆ©ç”¨å·²ç»æ‹Ÿåˆå¥½çš„çº¿æ€§æ¨¡å‹æ¥é¢„æµ‹å…¶ç»“æœã€‚æœ€å°äºŒä¹˜æ³•æ˜¯ç”¨çš„æ¯”è¾ƒå¹¿æ³›çš„ä¸€ç§æ–¹æ³•ã€‚
é«˜æ–¯äº 1823å¹´åœ¨è¯¯å·®ç‹¬ç«‹åŒåˆ†å¸ƒçš„å‡å®šä¸‹ï¼Œè¯æ˜äº†æœ€å°äºŒä¹˜æ–¹æ³•çš„ä¸€ä¸ªæœ€ä¼˜æ€§è´¨:åœ¨æ‰€æœ‰æ— åçš„çº¿æ€§ä¼°è®¡ç±»ä¸­, æœ€å°äºŒä¹˜æ–¹æ³•æ˜¯å…¶ä¸­æ–¹å·®æœ€å°çš„ï¼ å¯¹äºæ•°æ®(ğ‘¥ğ‘¥ğ‘–ğ‘–,ğ‘¦ğ‘¦ğ‘–ğ‘–)(ğ‘–ğ‘–=1,2,3...,n)ï¼Œæ‹Ÿåˆå‡ºå‡½æ•° â„(ğ‘¥)æœ‰è¯¯å·®ï¼Œå³æ®‹å·®ï¼šğ‘Ÿğ‘–=â„(ğ‘¥ğ‘–)âˆ’ğ‘¦ğ‘–ï¼Œæ­¤æ—¶ L2 èŒƒæ•°(æ®‹å·®å¹³æ–¹å’Œ) æœ€å°æ—¶ï¼Œ h(x) å’Œ yç›¸ä¼¼åº¦æœ€é«˜ï¼Œ æ›´æ‹Ÿåˆä¸€èˆ¬çš„ H(x) ä¸º næ¬¡çš„å¤šé¡¹å¼ï¼š
ğ»ğ»(ğ‘¥ğ‘¥)=ğ‘¤0+ğ‘¤1ğ‘¥+ğ‘¤2ğ‘¥2+...ğ‘¤ğ‘›ğ‘¥ğ‘›ï¼Œå…¶ä¸­w(w0,w1,w2,...,wn)ä¸ºå‚æ•°ï¼Œæœ€å°äºŒä¹˜æ³•å°±æ˜¯è¦æ‰¾åˆ°ä¸€ç»„w(w0,w1,w2,...,wn)ï¼Œä½¿å¾—æ®‹å·®å¹³æ–¹å’Œæœ€å°ã€‚
## ä¸‰ã€å®éªŒå†…å®¹
### 1ï¼æ­å»ºæœºå™¨å­¦ä¹ å¼€å‘å¹³å°ã€‚
#### ï¼ˆ1ï¼‰å®‰è£… Anacondaå¼€å‘å¹³å°ï¼Œä½¿ç”¨ jupyter notebookè¿›è¡Œç¼–è¾‘ã€‚
#### ï¼ˆ2ï¼‰å»ºç«‹è™šæ‹Ÿç¯å¢ƒï¼š
åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼šä½¿ç”¨ conda create -n your_env_name python=X.Xï¼ˆ3.6ã€3.8 ç­‰ï¼‰ï¼Œanacondaå‘½ä»¤åˆ›å»º pythonç‰ˆæœ¬ä¸º X.Xã€åå­—ä¸º your_env_name çš„è™šæ‹Ÿç¯å¢ƒã€‚your_env_name æ–‡ä»¶å¯ä»¥åœ¨ Anaconda å®‰è£…ç›®å½• envs æ–‡ä»¶ä¸‹æ‰¾åˆ°ã€‚
æ¿€ æ´» è™š æ‹Ÿ ç¯ å¢ƒ ï¼š ä½¿ ç”¨ å¦‚ ä¸‹ å‘½ ä»¤ å³ å¯ æ¿€ æ´» åˆ› å»º çš„ è™š æ‹Ÿ ç¯ å¢ƒactivate your_env_name(è™šæ‹Ÿç¯å¢ƒåç§°)ï¼Œæ­¤æ—¶ä½¿ç”¨ python --versionå¯ä»¥æ£€æŸ¥å½“å‰ pythonç‰ˆæœ¬æ˜¯å¦ä¸ºæƒ³è¦çš„ï¼ˆå³è™šæ‹Ÿç¯å¢ƒçš„ python ç‰ˆæœ¬ï¼‰ã€‚
é€€å‡ºè™šæ‹Ÿç¯å¢ƒï¼šä½¿ç”¨å¦‚ä¸‹å‘½ä»¤å³å¯é€€å‡ºåˆ›å»ºçš„è™šæ‹Ÿç¯å¢ƒ deactivate env_nameï¼Œ
ä¹Ÿå¯ä»¥ä½¿ç”¨â€œactivate rootâ€åˆ‡å› rootç¯å¢ƒã€‚
åˆ é™¤è™šæ‹Ÿç¯å¢ƒï¼šä½¿ç”¨å‘½ä»¤ conda remove -n your_env_name(è™šæ‹Ÿç¯å¢ƒåç§°) --al
å³å¯åˆ é™¤ã€‚
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1668700137806-417cd7f2-2fbb-4d17-a7a9-b72caa6d3624.png#averageHue=%23171717&clientId=u8c3edc07-3917-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=222&id=uba04a727&margin=%5Bobject%20Object%5D&name=image.png&originHeight=489&originWidth=1172&originalType=binary&ratio=1&rotation=0&showTitle=false&size=48755&status=done&style=none&taskId=u7b42c2fd-3a92-4282-b9ef-c8a132e6272&title=&width=532.7272611807203)
#### ï¼ˆ3ï¼‰  åœ¨è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…ç›¸åº”çš„åŒ…æ–‡ä»¶ï¼Œå¦‚ï¼špandasã€numpyã€matplotlibã€scipyã€sklearnç­‰ï¼Œå…·ä½“å®éªŒå¯å…·ä½“å®‰è£…ã€‚å¯ä»¥ä½¿ç”¨  conda list   å‘½ä»¤æŸ¥çœ‹å®‰è£…äº†å“ªäº›åŒ…ã€‚
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1668700269547-49670a6f-212b-4de1-84d4-c10db143ecbd.png#averageHue=%23181818&clientId=u8c3edc07-3917-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=512&id=u5b82a078&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1126&originWidth=1301&originalType=binary&ratio=1&rotation=0&showTitle=false&size=126490&status=done&style=none&taskId=udca60ee5-72e1-4338-a234-3513c8eff3f&title=&width=591.3636235461751)
### 2ï¼æœ€å°äºŒä¹˜æ³•å®ç°ã€‚
#### ï¼ˆ1ï¼‰   æœ€å°äºŒä¹˜æ³•çš„ pythonå®ç°ï¼šæˆ‘ä»¬ç”¨ç›®æ ‡å‡½æ•°ğ‘¦=ğ‘ ğ‘–ğ‘›2ğœ‹ğ‘¥,åŠ ä¸Šä¸€ä¸ªæ­£æ€åˆ†å¸ƒçš„å™ªéŸ³å¹²æ‰°ï¼Œå†ç”¨å¤šé¡¹å¼å»æ‹Ÿåˆï¼ˆåˆ†åˆ«å– 0 é˜¶ã€1 é˜¶ã€3 é˜¶ã€9 é˜¶è¿›è¡Œæ‹Ÿåˆï¼‰ã€‚ç¨‹åºæµç¨‹å¦‚ä¸‹ï¼š
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1668331157533-c923f3a5-792a-470f-a742-483e3ef5771f.png#averageHue=%23ebebeb&clientId=u3ecb4fef-37b1-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=133&id=u4a22f111&margin=%5Bobject%20Object%5D&name=image.png&originHeight=292&originWidth=933&originalType=binary&ratio=1&rotation=0&showTitle=false&size=53898&status=done&style=none&taskId=ue7821089-07fb-4890-b4b6-511d84e0a2c&title=&width=424.0908998989864)

å†™å‡ºä»£ç å’Œå¯è§†åŒ–ç»“æœã€‚
ç›®æ ‡å‡½æ•°ï¼šä»£å…¥ç”Ÿæˆçš„xï¼Œç”Ÿæˆå¯¹åº”çš„y
```python
def func(x):
return np.sin(2*np.pi*x)
```
éšæœºç”Ÿæˆ10ä¸ªxè¿›è¡Œå®éªŒï¼š
```python
x = np.linspace(0, 1, 10)
```
æ„é€ å¤šé¡¹å¼æ‹Ÿåˆå‡½æ•°ï¼š
```python
#å¤šé¡¹å¼
def fit_func(p,x):
"""
eg:p = np.poly1d([2,3,5,7])
print(p)==>>2x3 + 3x2 + 5x + 7
"""
f = np.poly1d(p)
return f(x)
```
è®¡ç®—è¯¯å·®ï¼š
```python
#æ®‹å·®
def residuals_func(p, x, y):
ret = fit_func(p, x) - y
return ret
```
leastsq æ˜¯ scipy åº“ è¿›è¡Œæœ€å°äºŒä¹˜æ³•è®¡ç®—çš„å‡½æ•°ï¼Œä¹Ÿå°±æ˜¯é€šè¿‡è¯¯å·®å‡½æ•°ä»¥åŠæ•°æ®ç‚¹è¿›è¡Œæˆ‘ä»¬å‰é¢è®²çš„å¯¹å‚æ•°è¿›è¡Œæ±‚å¯¼æ“ä½œï¼Œæœ€åå¾—å‡ºæˆ‘ä»¬æ‹Ÿåˆå‡ºæ¥çš„å‡½æ•°ã€‚
```python
def fitting(M=0):
"""
n ä¸º å¤šé¡¹å¼çš„æ¬¡æ•°
"""    
# éšæœºåˆå§‹åŒ–å¤šé¡¹å¼å‚æ•°
#numpy.random.rand(d0)çš„éšæœºæ ·æœ¬ä½äº[0, 1)ä¹‹é—´ã€‚d0è¡¨ç¤ºè¿”å›å¤šå°‘ä¸ª
	p_init = np.random.rand(M+1) #ç”ŸæˆM+1ä¸ªéšæœºæ•°çš„åˆ—è¡¨
# æœ€å°äºŒä¹˜æ³•
	p_lsq = leastsq(residuals_func, p_init, args=(x, y)) # ä¸‰ä¸ªå‚æ•°ï¼šè¯¯å·®å‡½æ•°ã€å‡½æ•°å‚æ•°åˆ—è¡¨ã€æ•°æ®ç‚¹
	print('Fitting Parameters:', p_lsq[0])

# å¯è§†åŒ–
	plt.plot(x_points, func(x_points), label='real')
	plt.plot(x_points, fit_func(p_lsq[0], x_points), label='fitted curve')
	plt.plot(x, y, 'bo', label='noise')
	plt.legend()
	return p_lsq

   # M=0
p_lsq = fitting(M=0)
```
æˆ‘ä»¬ä»ä¸€æ¬¡å‡½æ•°ä¾æ¬¡å¢åŠ é¡¹å¼ï¼Œæ‰¾åˆ°æœ€åˆé€‚çš„æ‹Ÿåˆæ›²çº¿ã€‚åˆ°9æ¬¡çš„æ—¶å€™ï¼Œå·²ç»è¿‡æ‹Ÿåˆè¿™äº›ç‚¹äº† ã€‚
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1668331267551-67477c92-7fe1-41b9-b3c2-7718821b4075.png#averageHue=%23faf9f8&clientId=u3ecb4fef-37b1-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=218&id=u855b1cf5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=480&originWidth=644&originalType=binary&ratio=1&rotation=0&showTitle=false&size=99139&status=done&style=none&taskId=u4d58a56a-b980-4331-9775-9295cc3a910&title=&width=292.7272663825801)
#### ï¼ˆ2ï¼‰   è¿‡æ‹Ÿåˆçš„æƒ…å†µä¸‹ï¼Œå¼•å…¥æ­£åˆ™åŒ–é¡¹è¿›è¡Œä¼˜åŒ–å®ç°ï¼Œå†™å‡ºä»£ç å’Œå¯è§†åŒ–ç»“æœã€‚
```python
def residuals_func_regularization_l1(p, x, y):
    """L1æ­£åˆ™åŒ–"""
    ret = fit_func(p, x) - y
    ret = np.append(ret, np.sqrt(regularization*abs(p))) # L1èŒƒæ•°ä½œä¸ºæ­£åˆ™åŒ–é¡¹
    return ret


def residuals_func_regularization_l2(p, x, y):
    """L2æ­£åˆ™åŒ–"""
    ret = fit_func(p, x) - y
    ret = np.append(ret, np.sqrt(0.5*regularization*np.square(p))) # L2èŒƒæ•°ä½œä¸ºæ­£åˆ™åŒ–é¡¹
    return ret

```

åŠ å…¥äº†æ­£åˆ™åŒ–çš„æœ€å°äºŒä¹˜æ³•
```python
def draw(M=9):
    p_lsq_M = fitting(M)
    # æœ€å°äºŒä¹˜æ³•,åŠ æ­£åˆ™åŒ–é¡¹
    p_init = np.random.rand(M+1)
    p_lsq_regularization_l1 = leastsq(residuals_func_regularization_l1, p_init, args=(x, y))
    p_lsq_regularization_l2 = leastsq(residuals_func_regularization_l2, p_init, args=(x, y))
    plt.plot(x_points, real_func(x_points), label='real')
    plt.plot(x_points, fit_func(p_lsq_M[0], x_points), label='fitted curve')
    plt.plot(x_points, fit_func(p_lsq_regularization_l1[0], x_points), label='regularization_l1')
    plt.plot(x_points, fit_func(p_lsq_regularization_l2[0], x_points), label='regularization_l2')
    plt.plot(x, y, 'bo', label='noise')
    plt.legend()
    plt.show()

```

![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1668700964247-c8c1368d-7d0d-48cc-95a1-7b4b59cad3f4.png#averageHue=%23fcfcfb&clientId=u8c3edc07-3917-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=348&id=u13f9c854&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1826&originWidth=3072&originalType=binary&ratio=1&rotation=0&showTitle=false&size=171379&status=done&style=none&taskId=u6a9182ce-9a07-4a9d-9859-3fed98ef1c3&title=&width=584.6448364257812)
å¯è§†åŒ–ç»“æœ
## å››ã€å®éªŒå®‰å…¨äº‹é¡¹
å®éªŒè¿‡ç¨‹ä¸­æ³¨æ„ç”¨ç”µå®‰å…¨ã€‚


## äº”ã€å®éªŒæäº¤æ–¹å¼
âˆš å®éªŒæŠ¥å‘Š      â–¡ç°åœºæ‰“åˆ†      â–¡çº¿ä¸Šå¹³å°æäº¤









# å®éªŒäºŒ çº¿æ€§åˆ†ç±»æ¨¡å‹
## ä¸€ã€å®éªŒç›®çš„
1. æŒæ¡æ„ŸçŸ¥æœºåŸç†åŠå®ç°ã€‚
2. æŒæ¡ K è¿‘é‚»åŸºæœ¬æ€æƒ³å’ŒåŸºæœ¬æ–¹æ³•ï¼ˆé‡éš¾ç‚¹ï¼‰ã€‚
3. äº†è§£æœ´ç´ è´å¶æ–¯åŸç†åŠå®ç°ã€‚
## äºŒã€å®éªŒåŸç†åŠè¯´æ˜
### 1. æ„ŸçŸ¥æœº
æ„ŸçŸ¥æœºæ˜¯æ ¹æ®è¾“å…¥å®ä¾‹çš„ç‰¹å¾å‘é‡ğ‘¥ğ‘¥x å¯¹å…¶è¿›è¡ŒäºŒç±»åˆ†ç±»çš„çº¿æ€§åˆ†ç±»æ¨¡å‹ï¼š
$ğ‘“(ğ‘¥)=sign(ğ‘¤â‹…ğ‘¥+ğ‘)$
æ„ŸçŸ¥æœºæ¨¡å‹å¯¹åº”äºè¾“å…¥ç©ºé—´ï¼ˆç‰¹å¾ç©ºé—´ï¼‰ä¸­çš„åˆ†ç¦»è¶…å¹³é¢ğ‘¤â‹…ğ‘¥+ğ‘=0
æ„ŸçŸ¥æœºå­¦ä¹ çš„ç­–ç•¥æ˜¯æå°åŒ–æŸå¤±å‡½æ•°ï¼š
$minğ¿(ğ‘¤,ğ‘)=âˆ’âˆ‘y_i(wâ‹…x_i+b)$ï¼Œå…¶ä¸­æŸå¤±å‡½æ•°å¯¹åº”äºè¯¯åˆ†ç±»ç‚¹åˆ°åˆ†ç¦»è¶…å¹³é¢çš„æ€»è·ç¦»ã€‚æ„ŸçŸ¥æœºå­¦ä¹ ç®—æ³•æ˜¯åŸºäºéšæœºæ¢¯åº¦ä¸‹é™æ³•çš„å¯¹æŸå¤±å‡½æ•°çš„æœ€ä¼˜åŒ–ç®—æ³•ï¼Œæœ‰åŸå§‹å½¢å¼å’Œå¯¹å¶å½¢å¼ã€‚ç®—æ³•ç®€å•ä¸”æ˜“äºå®ç°ã€‚åŸå§‹å½¢å¼ä¸­ï¼Œé¦–å…ˆä»»æ„é€‰å–ä¸€ä¸ªè¶…å¹³é¢ï¼Œç„¶åç”¨æ¢¯åº¦ä¸‹é™æ³•ä¸æ–­æå°åŒ–ç›®æ ‡å‡½æ•°ã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ä¸€æ¬¡éšæœºé€‰å–ä¸€ä¸ªè¯¯åˆ†ç±»ç‚¹ä½¿å…¶æ¢¯åº¦ä¸‹é™ã€‚
$ğ‘¤=ğ‘¤+ğœ‚y_ğ‘–ğ‘¥_i$
$b=b+ğœ‚y_i$
å½“å®ä¾‹ç‚¹è¢«è¯¯åˆ†ç±»ï¼Œå³ä½äºåˆ†ç¦»è¶…å¹³é¢çš„é”™è¯¯ä¾§ï¼Œåˆ™è°ƒæ•´ w, b çš„å€¼ï¼Œä½¿åˆ†ç¦»è¶…å¹³é¢å‘è¯¥æ— åˆ†ç±»ç‚¹çš„ä¸€ä¾§ç§»åŠ¨ï¼Œç›´è‡³è¯¯åˆ†ç±»ç‚¹è¢«æ­£ç¡®åˆ†ç±»ã€‚
### 2. K è¿‘é‚»
k è¿‘é‚»æ³•æ˜¯åŸºæœ¬ä¸”ç®€å•çš„åˆ†ç±»ä¸å›å½’æ–¹æ³•ã€‚k è¿‘é‚»æ³•çš„åŸºæœ¬åšæ³•æ˜¯ï¼šå¯¹ç»™å®šçš„è®­ç»ƒå®ä¾‹ç‚¹å’Œè¾“å…¥å®ä¾‹ç‚¹ï¼Œé¦–å…ˆç¡®å®šè¾“å…¥å®ä¾‹ç‚¹çš„ k ä¸ªæœ€è¿‘é‚»è®­ç»ƒå®ä¾‹ç‚¹ï¼Œç„¶ååˆ©ç”¨è¿™ kä¸ªè®­ç»ƒå®ä¾‹ç‚¹çš„ç±»çš„å¤šæ•°æ¥é¢„æµ‹è¾“å…¥å®ä¾‹ç‚¹çš„ç±»ã€‚
k è¿‘é‚»æ¨¡å‹å¯¹åº”äºåŸºäºè®­ç»ƒæ•°æ®é›†å¯¹ç‰¹å¾ç©ºé—´çš„ä¸€ä¸ªåˆ’åˆ†ã€‚k è¿‘é‚»æ³•ä¸­ï¼Œå½“è®­ç»ƒé›†ã€è·ç¦»åº¦é‡ã€k å€¼åŠåˆ†ç±»å†³ç­–è§„åˆ™ç¡®å®šåï¼Œå…¶ç»“æœå”¯ä¸€ç¡®å®šã€‚
k è¿‘é‚»æ³•ä¸‰è¦ç´ ï¼šè·ç¦»åº¦é‡ã€k å€¼çš„é€‰æ‹©å’Œåˆ†ç±»å†³ç­–è§„åˆ™ã€‚å¸¸ç”¨çš„è·ç¦»åº¦é‡æ˜¯æ¬§æ°è·ç¦»åŠæ›´ä¸€èˆ¬çš„ pL è·ç¦»ã€‚k å€¼å°æ—¶ï¼Œk è¿‘é‚»æ¨¡å‹æ›´å¤æ‚ï¼›k å€¼å¤§æ—¶ï¼Œk è¿‘é‚»æ¨¡å‹æ›´ç®€å•ã€‚k å€¼çš„é€‰æ‹©åæ˜ äº†å¯¹è¿‘ä¼¼è¯¯å·®ä¸ä¼°è®¡è¯¯å·®ä¹‹é—´çš„æƒè¡¡ï¼Œé€šå¸¸ç”±äº¤å‰éªŒè¯é€‰æ‹©æœ€ä¼˜çš„ kã€‚å¸¸ç”¨çš„åˆ†ç±»å†³ç­–è§„åˆ™æ˜¯å¤šæ•°è¡¨å†³ï¼Œå¯¹åº”äºç»éªŒé£é™©æœ€å°åŒ–ã€‚
k è¿‘é‚»æ³•çš„å®ç°éœ€è¦è€ƒè™‘å¦‚ä½•å¿«é€Ÿæœç´¢ k ä¸ªæœ€è¿‘é‚»ç‚¹ã€‚kd æ ‘æ˜¯ä¸€ç§ä¾¿äºå¯¹ k ç»´ç©ºé—´ä¸­çš„æ•°æ®è¿›è¡Œå¿«é€Ÿæ£€ç´¢çš„æ•°æ®ç»“æ„ã€‚kd æ ‘æ˜¯äºŒå‰æ ‘ï¼Œè¡¨ç¤ºå¯¹ k ç»´ç©ºé—´çš„ä¸€ä¸ªåˆ’åˆ†ï¼Œå…¶æ¯ä¸ªç»“ç‚¹å¯¹åº”äº k ç»´ç©ºé—´åˆ’åˆ†ä¸­çš„ä¸€ä¸ªè¶…çŸ©å½¢åŒºåŸŸã€‚åˆ©ç”¨ kd æ ‘å¯ä»¥çœå»å¯¹å¤§éƒ¨åˆ†æ•°æ®ç‚¹çš„æœç´¢ï¼Œä»è€Œå‡å°‘æœç´¢çš„è®¡ç®—é‡ã€‚
### 3. æœ´ç´ è´å¶æ–¯
æœ´ç´ è´å¶æ–¯æ³•æ˜¯å…¸å‹çš„ç”Ÿæˆå­¦ä¹ æ–¹æ³•ã€‚ç”Ÿæˆæ–¹æ³•ç”±è®­ç»ƒæ•°æ®å­¦ä¹ è”åˆæ¦‚ç‡åˆ†
å¸ƒ P(X,Y)ï¼Œç„¶åæ±‚å¾—åéªŒæ¦‚ç‡åˆ†å¸ƒ P(Y|X)ã€‚å…·ä½“æ¥è¯´ï¼Œåˆ©ç”¨è®­ç»ƒæ•°æ®å­¦ä¹  P(X|Y)å’Œ P(Y)çš„ä¼°è®¡ï¼Œå¾—åˆ°è”åˆæ¦‚ç‡åˆ†å¸ƒï¼šP(X,Y)ï¼P(Y)P(X|Y)å…¶ä¸­ï¼Œæ¦‚ç‡ä¼°è®¡æ–¹æ³•å¯ä»¥æ˜¯æå¤§ä¼¼ç„¶ä¼°è®¡æˆ–è´å¶æ–¯ä¼°è®¡ã€‚æœ´ç´ è´å¶æ–¯æ³•çš„åŸºæœ¬å‡è®¾æ˜¯æ¡ä»¶ç‹¬ç«‹æ€§:
$P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},...,X^{(n)}=x^{(n)}|Y=c_k)=\prod \limits_{j=0}^nP(X^{(j)}=x^{(j)}|Y=c_k)$
 è¿™æ˜¯ä¸€ä¸ªè¾ƒå¼ºçš„å‡è®¾ã€‚ç”±äºè¿™ä¸€å‡è®¾ï¼Œæ¨¡å‹åŒ…å«çš„æ¡ä»¶æ¦‚ç‡çš„æ•°é‡å¤§ä¸ºå‡å°‘ï¼Œæœ´ç´  è´å¶æ–¯æ³•çš„å­¦ä¹ ä¸é¢„æµ‹å¤§ä¸ºç®€åŒ–ã€‚å› è€Œæœ´ç´ è´å¶æ–¯æ³•é«˜æ•ˆï¼Œä¸”æ˜“äºå®ç°ã€‚å…¶ç¼ºç‚¹æ˜¯åˆ†ç±» çš„æ€§èƒ½ä¸ä¸€å®šå¾ˆé«˜ã€‚ æœ´ç´ è´å¶æ–¯æ³•åˆ©ç”¨è´å¶æ–¯å®šç†ä¸å­¦åˆ°çš„è”åˆæ¦‚ç‡æ¨¡å‹è¿›è¡Œåˆ†ç±»é¢„æµ‹  :
$P(Y|X)= \frac{P(Y)P(X|Y)}{\sum_YP(Y)P(X|Y)}$
 å°†è¾“å…¥ x åˆ†åˆ°åéªŒæ¦‚ç‡æœ€å¤§çš„ç±» yï¼š  
$y=\arg\max_{c_k}{P(Y=c_k)}\prod \limits_{j=i}^n{P(X_j=x^{(j)}|Y=c_k)}$
 åéªŒæ¦‚ç‡æœ€å¤§ç­‰ä»·äº 0-1 æŸå¤±å‡½æ•°æ—¶çš„æœŸæœ›é£é™©æœ€å°åŒ–ã€‚  
## ä¸‰ã€å®éªŒå†…å®¹
### 1ï¼åˆ©ç”¨é¸¢å°¾èŠ±æ•°æ®é›†æ„å»ºæ„ŸçŸ¥æœºæ¨¡å‹ã€‚
#### ï¼ˆ1ï¼‰IRIS æ•°æ®é›†ä¹Ÿç§°ä½œé¸¢å°¾èŠ±æ•°æ®é›†ï¼Œæ•´ä¸ªæ•°æ®é›†å…±æœ‰ 150 æ¡æ•°æ®ï¼Œåˆ†ä¸ºä¸‰ç±»ï¼Œæ¯ç±»50 æ¡æ•°æ®ï¼Œæ¯ä¸€æ¡æ•°æ®éƒ½æœ‰å››ä¸ªå±æ€§ï¼šèŠ±è¼é•¿åº¦ï¼ŒèŠ±è¼å®½åº¦ï¼ŒèŠ±ç“£é•¿åº¦ï¼ŒèŠ±ç“£å®½åº¦ï¼Œæ ‡ç­¾æ•°æ®å…±æœ‰ä¸‰ç§ï¼Œåˆ†åˆ«æ˜¯ Setosaï¼ŒVersicolourï¼ŒVirginicaã€‚å­¦ä¼šå¯¼å…¥æ•°æ®é›†ï¼Œå¹¶ä½œæ•°æ®çš„é¢„å¤„ç†ã€‚

```python
# load data
iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['label'] = iris.target

df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']

```
å¯¼å…¥æ•°æ®å¹¶é€‰å–æ•°æ®
```python
def draw_data():
    plt.scatter(df[:50]['sepal length'], df[:50]['sepal width'], label='0')
    plt.scatter(df[50:100]['sepal length'], df[50:100]['sepal width'], label='1')
    plt.scatter(df[100:150]['sepal length'], df[100:150]['sepal width'], label='2')
    plt.xlabel('sepal length')
    plt.ylabel('sepal width')
    plt.legend()
    plt.show()
```
æŸ¥çœ‹æ•°æ®
```python
data = np.array(df.iloc[:100, [0, 1, -1]])  # å‰100æ¡æ•°æ®ï¼Œå–ç¬¬ä¸€åˆ— ç¬¬äºŒåˆ— ç¬¬ä¸‰åˆ—
X, y = data[:,:-1], data[:,-1]  # åˆ‡ç‰‡ å–å‰ä¸¤åˆ—   å–åä¸€åˆ—
y = np.array([1 if i == 1 else -1 for i in y])  # è½¬æ¢æˆ1å’Œ-1ä¸¤ç±»

```
åˆ’åˆ†æ•°æ®
#### ï¼ˆ2ï¼‰ç”¨ python æ„å»ºæ„ŸçŸ¥æœºæ¨¡å‹ï¼Œå¹¶è¿›è¡Œå¯è§†åŒ–ã€‚
```python
class Model:
    def __init__(self):
        self.w = np.ones(len(data[0])-1, dtype=np.float32)
        self.b = 0
        self.l_rate = 0.1
        # self.data = data
    
    def sign(self, x, w, b):
        y = np.dot(x, w) + b
        return y
    
    # éšæœºæ¢¯åº¦ä¸‹é™æ³•
    def fit(self, X_train, y_train):
        is_wrong = False
        while not is_wrong:
            wrong_count = 0
            for d in range(len(X_train)):
                X = X_train[d]
                y = y_train[d]
                if y * self.sign(X, self.w, self.b) <= 0:
                    self.w = self.w + self.l_rate*np.dot(y, X)
                    self.b = self.b + self.l_rate*y
                    wrong_count += 1
            if wrong_count == 0:
                is_wrong = True
        return 'Perceptron Model!'
        
    def score(self):
        pass

```
æ„ŸçŸ¥æœºæ¨¡å‹æ„å»º

```python
perceptron = Model() # å»ºç«‹æ¨¡å‹
perceptron.fit(X, y)  # æ¨¡å‹æ‹Ÿåˆæ•°æ®ã€è®­ç»ƒ


x_points = np.linspace(4, 7,10)
y_ = -(perceptron.w[0]*x_points + perceptron.b)/perceptron.w[1]
# é¢„æµ‹ç»“æŸ
```
åˆ©ç”¨æ„ŸçŸ¥æœºè¿›è¡Œåˆ†ç±»
```python

plt.plot(x_points, y_)

plt.plot(data[:50, 0], data[:50, 1], 'bo', color='blue', label='0')
plt.plot(data[50:100, 0], data[50:100, 1], 'bo', color='orange', label='1')
plt.xlabel('sepal length')
plt.ylabel('sepal width')
plt.legend()
plt.show()

```
å¯è§†åŒ–
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1668731853891-e917a63b-00d6-4445-895a-9b94743ac4e8.png#averageHue=%23faf9f7&clientId=u8c3edc07-3917-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=496&id=u6292edd5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1092&originWidth=1284&originalType=binary&ratio=1&rotation=0&showTitle=false&size=58563&status=done&style=none&taskId=uf2b4e368-bf4a-4a08-bb18-cfaefcf51cc&title=&width=583.6363509863864)
å¯è§†åŒ–ç»“æœ
#### ï¼ˆ3ï¼‰åˆ©ç”¨ sklearn åº“è¿›è¡Œæ„ŸçŸ¥æœºæ¨¡å‹çš„æ„å»ºå’Œå¯è§†åŒ–ã€‚
è°ƒåŒ…æ¯”è¾ƒç®€å•ï¼Œåªéœ€è¦å¼•ç”¨sklearnåº“ä¸­çš„æ„ŸçŸ¥æœºæ¨¡å‹å»ºç«‹æ¨¡å‹å³å¯
```python
from sklearn.linear_model import Perceptron
clf = Perceptron()  # ä½¿ç”¨é»˜è®¤å‚æ•°
clf.fit(X, y)
print(clf.coef_) # æˆªè· Constants in decision function.
print(clf.intercept_)
x_ponits = np.arange(4, 8)
y_ = -(clf.coef_[0][0]*x_ponits + clf.intercept_)/clf.coef_[0][1]
# å¾—åˆ°ç»“æœ

```
å¯è§†åŒ–ç»“æœï¼š
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1668732065047-f5d562ff-c503-4a56-9443-452a2568de90.png#averageHue=%23faf9f7&clientId=u8c3edc07-3917-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=496&id=u5d2c2738&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1092&originWidth=1284&originalType=binary&ratio=1&rotation=0&showTitle=false&size=56099&status=done&style=none&taskId=u3ecfc9ad-5624-48f7-b894-56593411425&title=&width=583.6363509863864)
### 2ï¼åˆ©ç”¨ K è¿‘é‚»æ³•è¿›è¡Œé¸¢å°¾èŠ±ç±»åˆ«çš„é¢„æµ‹ã€‚
#### ï¼ˆ1ï¼‰K è¿‘é‚»çš„ python å®ç°ï¼šå»ºç«‹ä¸€ä¸ªç±» KNNï¼Œè¿›è¡Œæ¨¡å‹çš„æ„å»ºå’Œå¯è§†åŒ–ã€‚
æ„å»ºkè¿‘é‚»æ¨¡å‹
```python
class KNN:
    def __init__(self, X_train, y_train, n_neighbors=3, p=2):
        """
        parameter: n_neighbors ä¸´è¿‘ç‚¹ä¸ªæ•°
        parameter: p è·ç¦»åº¦é‡
        """
        self.n = n_neighbors
        self.p = p
        self.X_train = X_train
        self.y_train = y_train
    
    def predict(self, X):
        # å–å‡ºnä¸ªç‚¹
        knn_list = []
        for i in range(self.n):
            dist = np.linalg.norm(X - self.X_train[i], ord=self.p)
            knn_list.append((dist, self.y_train[i]))
            
        for i in range(self.n, len(self.X_train)):
            max_index = knn_list.index(max(knn_list, key=lambda x: x[0]))
            dist = np.linalg.norm(X - self.X_train[i], ord=self.p)
            if knn_list[max_index][0] > dist:
                knn_list[max_index] = (dist, self.y_train[i])
                
        # ç»Ÿè®¡
        knn = [k[-1] for k in knn_list]
        count_pairs = Counter(knn)
        max_count = sorted(count_pairs, key=lambda x:x)[-1]
        return max_count
    
    def score(self, X_test, y_test):
        right_count = 0
        n = 10
        for X, y in zip(X_test, y_test):
            label = self.predict(X)
            if label == y:
                right_count += 1
        return right_count / len(X_test)

clf = KNN(X_train, y_train)

clf.score(X_test, y_test)
```
æµ‹è¯•æ¨¡å‹ï¼š
```python
test_point = [6.0, 3.0]
print('Test Point: {}'.format(clf.predict(test_point)))
```
å¯è§†åŒ–ï¼š
```python
plt.scatter(df[:50]['sepal length'], df[:50]['sepal width'], label='0')
plt.scatter(df[50:100]['sepal length'], df[50:100]['sepal width'], label='1')
plt.plot(test_point[0], test_point[1], 'bo', label='test_point')
plt.xlabel('sepal length')
plt.ylabel('sepal width')
plt.legend()
plt.show()
```
#### ï¼ˆ2ï¼‰åˆ©ç”¨ sklearn åº“å®ç° KNN æ¨¡å‹çš„æ„å»ºå’Œå¯è§†åŒ–ã€‚
å¯¼å…¥åŒ…
```python
from sklearn.neighbors import KNeighborsClassifier
```

1. å…ˆé€‰å–ä¸¤ä¸ªç‰¹å¾ï¼Œå’Œä¸¤ä¸ªç±»è¿›è¡ŒäºŒåˆ†ç±»ï¼šï¼ˆåŸæœ¬æ•°æ®é›†é‡ŒèŠ±çš„ç‰¹å¾æœ‰å››ä¸ªè¿™é‡Œå–ä¸¤ä¸ªï¼ŒåŸæœ¬æ•°æ®é›†é‡ŒèŠ±æœ‰ä¸‰ç±»ï¼Œè¿™é‡Œå–ä¸¤ç±»ï¼‰
```python
def classify_2():  
    """äºŒåˆ†ç±»"""
    # data
    iris = load_iris()
    df = pd.DataFrame(iris.data, columns=iris.feature_names)
    df['label'] = iris.target
    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']
    # data = np.array(df.iloc[:100, [0, 1, -1]])

    """é¢„å¤„ç†ç»“æŸ"""

    data = np.array(df.iloc[:100, [0, 1, -1]])   # å–ç¬¬ä¸€ ç¬¬äºŒ ï¼ˆå‰ä¸¤ä¸ªæ˜¯ç‰¹å¾ï¼‰å€’æ•°ç¬¬ä¸€ï¼ˆè¿™ä¸ªæ˜¯æ ‡ç­¾ï¼Œå³æ˜¯è®­ç»ƒé›†çš„labelï¼‰
    X, y = data[:,:-1], data[:,-1] # Xæ˜¯ä¸¤ä¸ªç‰¹å¾   yæ˜¯0 1è¿™æ ·çš„labelä¿¡æ¯
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆè¿™é‡Œåº”è¯¥æ˜¯ä½œä¸ºæµ‹è¯•é›†ï¼‰

    clf_sk = KNeighborsClassifier() # æ„å»ºæ¨¡å‹
    clf_sk.fit(X_train, y_train)
    clf_sk.score(X_test, y_test)  # è¯„ä¼°æ¨¡å‹

    # é¢„æµ‹ æˆ‘è‡ªå·±éšä¾¿ç»™çš„ä¸¤ä¸ªæ•°æ®

    test_point = [[6.0, 3.0],[2.0,6.0]]
    print('Test Point: {}'.format(clf_sk.predict(test_point)))

     # ç”»å‡ºåˆ†å¸ƒå›¾

    plt.scatter(df[:50]['sepal length'], df[:50]['sepal width'], label='0')
    plt.scatter(df[50:100]['sepal length'], df[50:100]['sepal width'], label='1')
    plt.plot(test_point[0][0], test_point[0][1], 'bo', label='test_point')
    plt.xlabel('sepal length')
    plt.ylabel('sepal width')
    plt.legend()
    plt.show()

```
è¾“å‡ºç»“æœï¼š
> Test Point: 1.0

å³æ˜¯åˆ†ç±»çš„ç»“æœä¸ºç¬¬äºŒç±»ã€‚
å¯è§†åŒ–ç»“æœï¼š
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1668734197057-d60c9a6a-a358-45e8-b727-7824de6aaa3f.png#averageHue=%23f9f8f7&clientId=u8c3edc07-3917-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=496&id=uc4c253bc&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1092&originWidth=1284&originalType=binary&ratio=1&rotation=0&showTitle=false&size=48055&status=done&style=none&taskId=ubcd98b71-4aeb-4eef-8566-026744551c8&title=&width=583.6363509863864)

2. ç„¶åå°è¯•å¢åŠ ä¸€ä¸ªç±»é¢„æµ‹ï¼šï¼ˆåŸæœ¬æ•°æ®é›†é‡ŒèŠ±æœ‰ä¸‰ç±»ï¼Œè¿™é‡Œå–ä¸‰ç±»ï¼‰
```python
def classify_3():
    """ä¸‰åˆ†ç±»ï¼ŒäºŒç»´"""
        # data
    iris = load_iris()
    df = pd.DataFrame(iris.data, columns=iris.feature_names)
    df['label'] = iris.target
    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']
    # data = np.array(df.iloc[:100, [0, 1, -1]])

    """é¢„å¤„ç†ç»“æŸ"""

    data = np.array(df.iloc[:150, [0, 1, -1]])
    X, y = data[:,:-1], data[:,-1]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
    clf_sk = KNeighborsClassifier()
    clf_sk.fit(X_train, y_train)
    clf_sk.score(X_test, y_test)

    # # é¢„æµ‹ ä¸¤ä¸ªæ•°æ®

    test_point = [[6.0, 3.0],[5.0,2.0],[6,4]]
    print('Test Point: {}'.format(clf_sk.predict(test_point)))

    # # ç”»å‡ºåˆ†å¸ƒå›¾

    plt.scatter(df[:50]['sepal length'], df[:50]['sepal width'], label='0')
    plt.scatter(df[50:100]['sepal length'], df[50:100]['sepal width'], label='1')
    plt.scatter(df[100:150]['sepal length'], df[100:150]['sepal width'], label='2')
    num=0
    for [j,k] in test_point :
        num+=1
        plt.plot(j, k, 'bo', label='test_point'+str(num))
    plt.xlabel('sepal length')
    plt.ylabel('sepal width')
    plt.legend()
    plt.show()
```
è¾“å‡ºç»“æœï¼š
> Test Point: [1. 1. 0.]

å¯è§†åŒ–ç»“æœï¼š
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1668734274567-305c1849-65eb-42bd-925a-4a0caa9d1779.png#averageHue=%23f8f7f7&clientId=u8c3edc07-3917-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=496&id=u202606d5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1092&originWidth=1284&originalType=binary&ratio=1&rotation=0&showTitle=false&size=58662&status=done&style=none&taskId=ue5a7a5da-d49e-4650-bb40-39f7bab51e8&title=&width=583.6363509863864)

3. å–æ•°æ®é›†é‡Œçš„å››ä¸ªç‰¹å¾ï¼Œç”¨knnè¿›è¡Œä¸‰åˆ†ç±»ï¼š
```python
def classify_3_4D():
    """ä¸‰åˆ†ç±»ï¼Œå››ç»´"""
        # data
    iris = load_iris()
    df = pd.DataFrame(iris.data, columns=iris.feature_names)
    df['label'] = iris.target
    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']
    # data = np.array(df.iloc[:100, [0, 1, -1]])

    """é¢„å¤„ç†ç»“æŸ"""

    data = np.array(df.iloc[:150, [0, 1, 2, 3, 4]])
    print(data)
    X, y = data[:,:-1], data[:,-1]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
    clf_sk = KNeighborsClassifier()
    clf_sk.fit(X_train, y_train)
    print("é¢„æµ‹å‡†ç¡®åº¦ä¸ºï¼š{}".format(clf_sk.score(X_test, y_test)))
    # å››ç»´é¢„æµ‹æ²¡é—®é¢˜ï¼Œä½†æ˜¯ç”»å›¾å’±è¿™ä¸‰ç»´ç©ºé—´è¿˜æ˜¯ç®—äº†ï¼Œå¦‚æœç¡¬æ˜¯è¦ç”»å›¾ï¼Œå¯ä»¥å…ˆèšç±»ï¼Œå››ç±»å˜3ç±»æˆ–è€…2ç±»ï¼Œå†åˆ†ç±»å¹¶ç”»å›¾
    # # é¢„æµ‹ ä¸‰ä¸ªæ•°æ®

    test_point = [[6.0, 3.0,3.0,2.0],[5.0,2.0,3.0,3.0],[6,4,2,2]]
    print('Test Point: {}'.format(clf_sk.predict(test_point)))
    # å››ç»´é¢„æµ‹æ²¡é—®é¢˜ï¼Œä½†æ˜¯ç”»å›¾å’±è¿™ä¸‰ç»´ç©ºé—´è¿˜æ˜¯ç®—äº†ï¼Œå¦‚æœç¡¬æ˜¯è¦ç”»å›¾ï¼Œå¯ä»¥å…ˆèšç±»ï¼Œå››ç±»å˜3ç±»æˆ–è€…2ç±»ï¼Œå†åˆ†ç±»å¹¶ç”»å›¾
    
```
é¢„æµ‹ç»“æœï¼š
> æ¨¡å‹é¢„æµ‹å‡†ç¡®åº¦ä¸ºï¼š0.9666666666666667
> Test Point: [1. 1. 0.]

åœ¨ sklearn åº“ä¸­ï¼ŒKNeighborsClassifier æ˜¯å®ç° K è¿‘é‚»ç®—æ³•çš„ä¸€ä¸ªç±»ï¼Œä¸€èˆ¬éƒ½ä½¿ç”¨æ¬§
å¼è·ç¦»è¿›è¡Œæµ‹é‡ã€‚è¿™ä¸ªç±»çš„ç»“æ„å¦‚ä¸‹ï¼š class sklearn.neighbors. KNeighborsClassifier 
( n_neighbors=5, weights=â€™uniformâ€™, algorithm=â€™autoâ€™, leaf_size=30, p=2, 
metric=â€™minkowskiâ€™, metric_params=None, n_jobs=1, **kwargs ) n_neighborsï¼šå°±æ˜¯é€‰å–æœ€
è¿‘çš„ç‚¹çš„ä¸ªæ•°ï¼šk leaf_sizeï¼šè¿™ä¸ªæ˜¯æ„é€ æ ‘çš„å¤§å°ï¼Œå€¼ä¸€èˆ¬é€‰å–é»˜è®¤å€¼å³å¯ï¼Œå¤ªå¤§ä¼šå½±
å“é€Ÿåº¦ã€‚ n_jobs ï¼šé»˜è®¤å€¼ 1ï¼Œé€‰å–-1 å æ® CPU æ¯”é‡ä¼šå‡å°ï¼Œä½†è¿è¡Œé€Ÿåº¦ä¹Ÿä¼šå˜æ…¢ï¼Œæ‰€
æœ‰çš„ core éƒ½ä¼šè¿è¡Œã€‚ algorithm: è¿‘é‚»ç®—æ³•ï¼Œå¯é€‰{'auto', 'ball_tree', 'kd_tree', 'brute'}ã€‚
#### ï¼ˆ3ï¼‰æ„é€ å¹³è¡¡ Kd æ ‘ï¼Œå¹¶å®ç°ä¹¦ä¸­ä¾‹é¢˜ 3.2ã€‚
```python
class KdNode(object):
    def __init__(self, dom_elt, split, left, right):
        self.dom_elt = dom_elt  # kç»´å‘é‡èŠ‚ç‚¹(kç»´ç©ºé—´ä¸­çš„ä¸€ä¸ªæ ·æœ¬ç‚¹)
        self.split = split      # æ•´æ•°ï¼ˆè¿›è¡Œåˆ†å‰²ç»´åº¦çš„åºå·ï¼‰
        self.left = left        # è¯¥ç»“ç‚¹åˆ†å‰²è¶…å¹³é¢å·¦å­ç©ºé—´æ„æˆçš„kd-tree
        self.right = right      # è¯¥ç»“ç‚¹åˆ†å‰²è¶…å¹³é¢å³å­ç©ºé—´æ„æˆçš„kd-tree
```
åˆ›å»ºkdæ ‘ä»£ç ï¼š
```python
class KdTree(object):
    def __init__(self, data):
 
        def CreateNode(split, data_set):  # æŒ‰ç¬¬splitç»´åˆ’åˆ†æ•°æ®é›†exsetåˆ›å»ºKdNode
            if not data_set:              # æ•°æ®é›†ä¸ºç©º
                return None
            # keyå‚æ•°çš„å€¼ä¸ºä¸€ä¸ªå‡½æ•°ï¼Œæ­¤å‡½æ•°åªæœ‰ä¸€ä¸ªå‚æ•°ä¸”è¿”å›ä¸€ä¸ªå€¼ç”¨æ¥è¿›è¡Œæ¯”è¾ƒ
            # operatoræ¨¡å—æä¾›çš„itemgetterå‡½æ•°ç”¨äºè·å–å¯¹è±¡çš„å“ªäº›ç»´çš„æ•°æ®ï¼Œå‚æ•°ä¸ºéœ€è¦è·å–çš„æ•°æ®åœ¨å¯¹è±¡ä¸­çš„åºå·
            data_set.sort(key=operator.itemgetter(split)) # æŒ‰è¦è¿›è¡Œåˆ†å‰²çš„é‚£ä¸€ç»´æ•°æ®æ’åº  ä»å°åˆ°å¤§æ’åº
            #data_set.sort(key=lambda x: x[split])
            split_pos = len(data_set) // 2     # //ä¸ºPythonä¸­çš„æ•´æ•°é™¤æ³•
            median = data_set[split_pos]       # ä¸­ä½æ•°åˆ†å‰²ç‚¹
            leftdata=data_set[:split_pos]
            rightdata=data_set[split_pos+1:]
            split_next1=np.argmax(np.var(leftdata,0))
            split_next2=np.argmax(np.var(rightdata,0))
            # é€’å½’çš„åˆ›å»ºkdæ ‘
            return KdNode(median, split, CreateNode(split_next1,leftdata), CreateNode(split_next2, rightdata))
                                           
 
        self.root = CreateNode(0, data)  # ä»ç¬¬0ç»´åˆ†é‡å¼€å§‹æ„å»ºkdæ ‘,è¿”å›æ ¹èŠ‚ç‚¹
```
ä¹¦ä¸Šé¢˜3.2ï¼š
ç»™å®šä¸€ä¸ªäºŒç»´ç©ºé—´çš„æ•°æ®é›†ï¼š
T={(2,3)T,(5,4)T,(9,6)T,(4,7)T,(8,1)T,(7,2)T}æ„é€ ä¸€ä¸ªå¹³è¡¡kdæ ‘
```python
# KDTreeçš„å‰åºéå†
def preorder(root):
    print(root.dom_elt)
    if root.left:  # èŠ‚ç‚¹ä¸ä¸ºç©º
        preorder(root.left)
    if root.right:
        preorder(root.right)
 
 
if __name__ == "__main__":
    data = [[2, 3], [5, 4], [9, 6], [4, 7], [8, 1], [7, 2]]
    kd = KdTree(data)
    preorder(kd.root)
```
æ„é€ å®Œæˆ
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1669707442831-e3b5293f-7228-4a47-9e62-d3f5dde4462c.png#averageHue=%230e0021&clientId=u1554ef67-f7a1-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=131&id=u14b2b9fa&margin=%5Bobject%20Object%5D&name=image.png&originHeight=289&originWidth=1093&originalType=binary&ratio=1&rotation=0&showTitle=false&size=21175&status=done&style=none&taskId=u43683d98-7613-4747-9aa4-cc5cc79d30b&title=&width=496.818171049938)
### 3. åœ¨é¸¢å°¾èŠ±æ•°æ®é›†ä¸Šç”¨é«˜æ–¯æœ´ç´ è´å¶æ–¯å®ç°åˆ†ç±»ï¼Œå¹¶è¿›è¡Œé¢„æµ‹ã€‚ç›´æ¥ä½¿ç”¨ sklearn æ–¹æ³•ã€‚
æ‰‹å†™ä»£ç ï¼ˆé«˜æ–¯æœ´ç´ è´å¶æ–¯ï¼‰ï¼š
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
# è¿™ä¸ªä¸ç®—æ˜¯åŒ…çš„å†…å®¹ï¼Œåªæ˜¯ç”¨æ¥è·å–æ•°æ®é›†å’Œåˆ’åˆ†æ•°æ®é›†ç”¨çš„
from collections import Counter
import math

```
æ•°æ®é¢„å¤„ç†ï¼š
```python
# data
def create_data():
Â  Â  iris = load_iris()
Â  Â  df = pd.DataFrame(iris.data, columns=iris.feature_names)
Â  Â  df['label'] = iris.target
Â  Â  df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']
Â  Â  data = np.array(df.iloc[:100, :])
Â  Â  # print(data)
Â  Â  return data[:,:-1], data[:,-1]


X, y = create_data()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
X_test[0], y_test[0]
```

```python
class NaiveBayes:
    def __init__(self):
        self.model = None

    # æ•°å­¦æœŸæœ›
    @staticmethod
    def mean(X):
        return sum(X) / float(len(X))

    # æ ‡å‡†å·®ï¼ˆæ–¹å·®ï¼‰
    def stdev(self, X):
        avg = self.mean(X)
        return math.sqrt(sum([pow(x-avg, 2) for x in X]) / float(len(X)))

    # æ¦‚ç‡å¯†åº¦å‡½æ•°
    def gaussian_probability(self, x, mean, stdev):
        exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))
        return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent

    # å¤„ç†X_train
    def summarize(self, train_data):
        summaries = [(self.mean(i), self.stdev(i)) for i in zip(*train_data)]
        return summaries

    # åˆ†ç±»åˆ«æ±‚å‡ºæ•°å­¦æœŸæœ›å’Œæ ‡å‡†å·®
    def fit(self, X, y):
        labels = list(set(y))
        data = {label:[] for label in labels}
        for f, label in zip(X, y):
            data[label].append(f)
        self.model = {label: self.summarize(value) for label, value in data.items()}
        return 'gaussianNB train done!'

    # è®¡ç®—æ¦‚ç‡
    def calculate_probabilities(self, input_data):
        # summaries:{0.0: [(5.0, 0.37),(3.42, 0.40)], 1.0: [(5.8, 0.449),(2.7, 0.27)]}
        # input_data:[1.1, 2.2]
        probabilities = {}
        for label, value in self.model.items():
            probabilities[label] = 1
            for i in range(len(value)):
                mean, stdev = value[i]
                probabilities[label] *= self.gaussian_probability(input_data[i], mean, stdev)
        return probabilities

    # ç±»åˆ«
    def predict(self, X_test):
        # {0.0: 2.9680340789325763e-27, 1.0: 3.5749783019849535e-26}
        label = sorted(self.calculate_probabilities(X_test).items(), key=lambda x: x[-1])[-1][0]
        return label

    def score(self, X_test, y_test):
        right = 0
        for X, y in zip(X_test, y_test):
            label = self.predict(X)
            if label == y:
                right += 1

        return right / float(len(X_test))

odel = NaiveBayes()
# define
model.fit(X_train, y_train)
# fit
print(model.predict([4.4,  3.2,  1.3,  0.2]))
# é¢„æµ‹
model.score(X_test, y_test)
```
è¾“å‡ºï¼š
```python

0
```
å³æ˜¯ç¬¬ä¸€ç±»ã€‚
åŒä¸Šï¼Œè°ƒåŒ…å®ç°ä¼šæ›´ç®€å•ï¼š
```python
from sklearn.naive_bayes import GaussianNB
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

from collections import Counter
import math

# data
def create_data():
    iris = load_iris()
    df = pd.DataFrame(iris.data, columns=iris.feature_names)
    df['label'] = iris.target
    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']
    data = np.array(df.iloc[:100, :])
    # print(data)
    return data[:,:-1], data[:,-1]

X, y = create_data()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
X_test[0], y_test[0]
"""æ•°æ®é¢„å¤„ç†ç»“æŸ"""


clf = GaussianNB()
clf.fit(X_train, y_train)
clf.score(X_test, y_test)
print(clf.predict([[4.4,  3.2,  1.3,  0.2]]))
```
è¾“å‡ºï¼š
```python
[0,]
```
å³æ˜¯ç¬¬ä¸€ç±»ã€‚
## å››ã€å®éªŒå®‰å…¨äº‹é¡¹
å®éªŒè¿‡ç¨‹ä¸­æ³¨æ„ç”¨ç”µå®‰å…¨ã€‚ 
## äº”ã€å®éªŒæäº¤æ–¹å¼ 
âˆš å®éªŒæŠ¥å‘Š â–¡ ç°åœºæ‰“åˆ† â–¡ çº¿ä¸Šå¹³å°æäº¤  

# å®éªŒä¸‰ å†³ç­–æ ‘ä¸éšæœºæ£®æ—
## ä¸€ã€å®éªŒç›®çš„

1. æŒæ¡å†³ç­–æ ‘åŸç†åŠå®ç°ã€‚
2. æŒæ¡ ID3 ç®—æ³•å®ç°ï¼ˆé‡ç‚¹ï¼‰ã€‚
3. æŒæ¡ sklearn åº“ä¸­å†³ç­–æ ‘çš„å®ç°æ–¹æ³•ï¼ˆCART æ ‘ç®—æ³•ï¼‰ã€‚
4. äº†è§£éšæœºæ£®æ—åŸç†åŠå®ç°ï¼ˆåŠ åˆ†é¡¹ï¼‰ã€‚
## äºŒã€å®éªŒåŸç†åŠè¯´æ˜

1. å†³ç­–æ ‘
å†³ç­–æ ‘ï¼ˆdecision treeï¼‰ï¼šæ˜¯ä¸€ç§åŸºæœ¬çš„åˆ†ç±»ä¸å›å½’æ–¹æ³•ï¼Œæ­¤å¤„ä¸»è¦è®¨è®ºåˆ†ç±»çš„å†³ç­–æ ‘ã€‚åœ¨åˆ†ç±»é—®é¢˜ä¸­ï¼Œè¡¨ç¤ºåŸºäºç‰¹å¾å¯¹å®ä¾‹è¿›è¡Œåˆ†ç±»çš„è¿‡ç¨‹ï¼Œå¯ä»¥è®¤ä¸ºæ˜¯ if-then çš„é›†åˆï¼Œä¹Ÿå¯ä»¥è®¤ä¸ºæ˜¯å®šä¹‰åœ¨ç‰¹å¾ç©ºé—´ä¸ç±»ç©ºé—´ä¸Šçš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒã€‚
å†³ç­–æ ‘é€šå¸¸æœ‰ä¸‰ä¸ªæ­¥éª¤ï¼šç‰¹å¾é€‰æ‹©ã€å†³ç­–æ ‘çš„ç”Ÿæˆã€å†³ç­–æ ‘çš„ä¿®å‰ªã€‚
ç”¨å†³ç­–æ ‘åˆ†ç±»ï¼šä»æ ¹èŠ‚ç‚¹å¼€å§‹ï¼Œå¯¹å®ä¾‹çš„æŸä¸€ç‰¹å¾è¿›è¡Œæµ‹è¯•ï¼Œæ ¹æ®æµ‹è¯•ç»“æœå°†å®ä¾‹åˆ†é…åˆ°å…¶å­èŠ‚ç‚¹ï¼Œæ­¤æ—¶æ¯ä¸ªå­èŠ‚ç‚¹å¯¹åº”ç€è¯¥ç‰¹å¾çš„ä¸€ä¸ªå–å€¼ï¼Œå¦‚æ­¤é€’å½’çš„å¯¹å®ä¾‹è¿›è¡Œæµ‹è¯•å¹¶åˆ†é…ï¼Œç›´åˆ°åˆ°è¾¾å¶èŠ‚ç‚¹ï¼Œæœ€åå°†å®ä¾‹åˆ†åˆ°å¶èŠ‚ç‚¹çš„ç±»ä¸­ã€‚
å†³ç­–æ ‘çš„æ„é€ 
å†³ç­–æ ‘å­¦ä¹ çš„ç®—æ³•é€šå¸¸æ˜¯ä¸€ä¸ªé€’å½’åœ°é€‰æ‹©æœ€ä¼˜ç‰¹å¾ï¼Œå¹¶æ ¹æ®è¯¥ç‰¹å¾å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œåˆ†å‰²ï¼Œä½¿å¾—å„ä¸ªå­æ•°æ®é›†æœ‰ä¸€ä¸ªæœ€å¥½çš„åˆ†ç±»çš„è¿‡ç¨‹ã€‚è¿™ä¸€è¿‡ç¨‹å¯¹åº”ç€å¯¹ç‰¹å¾ç©ºé—´çš„åˆ’åˆ†ï¼Œä¹Ÿå¯¹åº”ç€å†³ç­–æ ‘çš„æ„å»ºã€‚
1ï¼‰ å¼€å§‹ï¼šæ„å»ºæ ¹èŠ‚ç‚¹ï¼Œå°†æ‰€æœ‰è®­ç»ƒæ•°æ®éƒ½æ”¾åœ¨æ ¹èŠ‚ç‚¹ï¼Œé€‰æ‹©ä¸€ä¸ªæœ€ä¼˜ç‰¹å¾ï¼ŒæŒ‰ç€è¿™ä¸€ç‰¹å¾å°†è®­ç»ƒæ•°æ®é›†åˆ†å‰²æˆå­é›†ï¼Œä½¿å¾—å„ä¸ªå­é›†æœ‰ä¸€ä¸ªåœ¨å½“å‰æ¡ä»¶ä¸‹æœ€å¥½çš„åˆ†ç±»ã€‚
2ï¼‰ å¦‚æœè¿™äº›å­é›†å·²ç»èƒ½å¤Ÿè¢«åŸºæœ¬æ­£ç¡®åˆ†ç±»ï¼Œé‚£ä¹ˆæ„å»ºå¶èŠ‚ç‚¹ï¼Œå¹¶å°†è¿™äº›å­é›†åˆ†åˆ°æ‰€å¯¹åº”çš„å¶èŠ‚ç‚¹å»ã€‚
3ï¼‰å¦‚æœè¿˜æœ‰å­é›†ä¸èƒ½å¤Ÿè¢«æ­£ç¡®çš„åˆ†ç±»ï¼Œé‚£ä¹ˆå°±å¯¹è¿™äº›å­é›†é€‰æ‹©æ–°çš„æœ€ä¼˜ç‰¹å¾ï¼Œç»§ç»­å¯¹å…¶è¿›è¡Œåˆ†å‰²ï¼Œæ„å»ºç›¸åº”çš„èŠ‚ç‚¹ï¼Œå¦‚æœé€’å½’è¿›è¡Œï¼Œç›´è‡³æ‰€æœ‰è®­ç»ƒæ•°æ®å­é›†è¢«åŸºæœ¬æ­£ç¡®çš„åˆ†ç±»ï¼Œæˆ–è€…æ²¡æœ‰åˆé€‚çš„ç‰¹å¾ä¸ºæ­¢ã€‚
4ï¼‰æ¯ä¸ªå­é›†éƒ½è¢«åˆ†åˆ°å¶èŠ‚ç‚¹ä¸Šï¼Œå³éƒ½æœ‰äº†æ˜ç¡®çš„ç±»ï¼Œè¿™æ ·å°±ç”Ÿæˆäº†ä¸€é¢—å†³ç­–æ ‘ã€‚

2. éšæœºæ£®æ—
å°½ç®¡æœ‰å‰ªæç­‰æ–¹æ³•ï¼Œä¸€æ£µæ ‘çš„ç”Ÿæˆè‚¯å®šè¿˜æ˜¯ä¸å¦‚å¤šæ£µæ ‘ï¼Œå› æ­¤å°±æœ‰äº†éšæœºæ£®æ—ï¼Œè§£å†³å†³ç­–æ ‘æ³›åŒ–èƒ½åŠ›å¼±çš„ç¼ºç‚¹ã€‚
è€ŒåŒä¸€æ‰¹æ•°æ®ï¼Œç”¨åŒæ ·çš„ç®—æ³•åªèƒ½äº§ç”Ÿä¸€æ£µæ ‘ï¼Œè¿™æ—¶ Bagging ç­–ç•¥å¯ä»¥å¸®åŠ©æˆ‘ä»¬äº§ç”Ÿä¸åŒçš„æ•°æ®é›†ã€‚Bagging ç­–ç•¥æ¥æºäº bootstrap aggregationï¼šä»æ ·æœ¬é›†ï¼ˆå‡è®¾æ ·æœ¬é›† Nä¸ªæ•°æ®ç‚¹ï¼‰ä¸­é‡é‡‡æ ·é€‰å‡º Nb ä¸ªæ ·æœ¬ï¼ˆæœ‰æ”¾å›çš„é‡‡æ ·ï¼Œæ ·æœ¬æ•°æ®ç‚¹ä¸ªæ•°ä»ç„¶ä¸å˜ä¸º Nï¼‰ï¼Œåœ¨æ‰€æœ‰æ ·æœ¬ä¸Šï¼Œå¯¹è¿™ n ä¸ªæ ·æœ¬å»ºç«‹åˆ†ç±»å™¨ï¼ˆID3\C4.5\CART\SVM\LOGISTICï¼‰ï¼Œé‡å¤ä»¥ä¸Šä¸¤æ­¥ m æ¬¡ï¼Œè·å¾— m ä¸ªåˆ†ç±»å™¨ï¼Œæœ€åæ ¹æ®è¿™ m ä¸ªåˆ†ç±»å™¨çš„æŠ•ç¥¨ç»“æœï¼Œå†³å®šæ•°æ®å±äºå“ªä¸€ç±»ã€‚
éšæœºæ£®æ—åœ¨ bagging çš„åŸºç¡€ä¸Šæ›´è¿›ä¸€æ­¥ï¼š
3. æ ·æœ¬çš„éšæœºï¼šä»æ ·æœ¬é›†ä¸­ç”¨ Bootstrap éšæœºé€‰å– n ä¸ªæ ·æœ¬
4. ç‰¹å¾çš„éšæœºï¼šä»æ‰€æœ‰å±æ€§ä¸­éšæœºé€‰å– K ä¸ªå±æ€§ï¼Œé€‰æ‹©æœ€ä½³åˆ†å‰²å±æ€§ä½œä¸ºèŠ‚ç‚¹å»ºç«‹ CART å†³ç­–æ ‘ï¼ˆæ³›åŒ–çš„ç†è§£ï¼Œè¿™é‡Œé¢ä¹Ÿå¯ä»¥æ˜¯å…¶ä»–ç±»å‹çš„åˆ†ç±»å™¨ï¼Œæ¯”å¦‚ SVMã€Logisticsï¼‰
5. é‡å¤ä»¥ä¸Šä¸¤æ­¥ m æ¬¡ï¼Œå³å»ºç«‹äº† m æ£µ CART å†³ç­–æ ‘
6. è¿™ m ä¸ª CART å½¢æˆéšæœºæ£®æ—ï¼Œé€šè¿‡æŠ•ç¥¨è¡¨å†³ç»“æœï¼Œå†³å®šæ•°æ®å±äºå“ªä¸€ç±»ï¼ˆæŠ•ç¥¨æœºåˆ¶æœ‰ä¸€ç¥¨å¦å†³åˆ¶ã€å°‘æ•°æœä»å¤šæ•°ã€åŠ æƒå¤šæ•°ï¼‰
## ä¸‰ã€å®éªŒå†…å®¹
### 1. ID3 ç®—æ³•å®ç°ã€‚
#### ï¼ˆ1ï¼‰ç¼–å†™ä»£ç è®¡ç®—ä¿¡æ¯å¢ç›Šï¼Œæ•°æ®é›†ä¸ºæ•™æ 71 é¡µè¡¨ 5.1ã€‚
æ•°æ®é›†æ„é€ ï¼š
```python

datasets = [['é’å¹´', 'å¦', 'å¦', 'ä¸€èˆ¬', 'å¦'],
               ['é’å¹´', 'å¦', 'å¦', 'å¥½', 'å¦'],
               ['é’å¹´', 'æ˜¯', 'å¦', 'å¥½', 'æ˜¯'],
               ['é’å¹´', 'æ˜¯', 'æ˜¯', 'ä¸€èˆ¬', 'æ˜¯'],
               ['é’å¹´', 'å¦', 'å¦', 'ä¸€èˆ¬', 'å¦'],
               ['ä¸­å¹´', 'å¦', 'å¦', 'ä¸€èˆ¬', 'å¦'],
               ['ä¸­å¹´', 'å¦', 'å¦', 'å¥½', 'å¦'],
               ['ä¸­å¹´', 'æ˜¯', 'æ˜¯', 'å¥½', 'æ˜¯'],
               ['ä¸­å¹´', 'å¦', 'æ˜¯', 'éå¸¸å¥½', 'æ˜¯'],
               ['ä¸­å¹´', 'å¦', 'æ˜¯', 'éå¸¸å¥½', 'æ˜¯'],
               ['è€å¹´', 'å¦', 'æ˜¯', 'éå¸¸å¥½', 'æ˜¯'],
               ['è€å¹´', 'å¦', 'æ˜¯', 'å¥½', 'æ˜¯'],
               ['è€å¹´', 'æ˜¯', 'å¦', 'å¥½', 'æ˜¯'],
               ['è€å¹´', 'æ˜¯', 'å¦', 'éå¸¸å¥½', 'æ˜¯'],
               ['è€å¹´', 'å¦', 'å¦', 'ä¸€èˆ¬', 'å¦'],
               ]
labels = [u'å¹´é¾„', u'æœ‰å·¥ä½œ', u'æœ‰è‡ªå·±çš„æˆ¿å­', u'ä¿¡è´·æƒ…å†µ', u'ç±»åˆ«']
```
æŒ‰ç…§å…¬å¼å†™å‡ºè®¡ç®—ä¿¡æ¯å¢ç›Šçš„ä»£ç ï¼š
```python

# ç†µ
def calc_ent(datasets):
    data_length = len(datasets)
    label_count = {}
    for i in range(data_length):
        label = datasets[i][-1]
        if label not in label_count:
            label_count[label] = 0
        label_count[label] += 1
    ent = -sum([(p/data_length)*log(p/data_length, 2) for p in label_count.values()])
    return ent

# ç»éªŒæ¡ä»¶ç†µ
def cond_ent(datasets, axis=0):
    data_length = len(datasets)
    feature_sets = {}
    for i in range(data_length):
        feature = datasets[i][axis]
        if feature not in feature_sets:
            feature_sets[feature] = []
        feature_sets[feature].append(datasets[i])
    cond_ent = sum([(len(p)/data_length)*calc_ent(p) for p in feature_sets.values()])
    return cond_ent

# ä¿¡æ¯å¢ç›Š
def info_gain(ent, cond_ent):
    return ent - cond_ent

```
è·å–ä¿¡æ¯å¢ç›Šï¼š
```python
def info_gain_train(datasets):
    count = len(datasets[0]) - 1
    ent = calc_ent(datasets)
    best_feature = []
    for c in range(count):
        c_info_gain = info_gain(ent, cond_ent(datasets, axis=c))
        best_feature.append((c, c_info_gain))
        print('ç‰¹å¾({}) - info_gain - {:.3f}'.format(labels[c], c_info_gain))
    # æ¯”è¾ƒå¤§å°
    best_ = max(best_feature, key=lambda x: x[-1])
    return 'ç‰¹å¾({})çš„ä¿¡æ¯å¢ç›Šæœ€å¤§ï¼Œé€‰æ‹©ä¸ºæ ¹èŠ‚ç‚¹ç‰¹å¾'.format(labels[best_[0]])


info_gain_train(np.array(datasets))
```
è¾“å‡ºç»“æœï¼š
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1669707672040-1ad03759-9479-4b6f-82bf-dd110dc6dcb3.png#averageHue=%230f0123&clientId=u1554ef67-f7a1-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=71&id=u8b028dea&margin=%5Bobject%20Object%5D&name=image.png&originHeight=157&originWidth=624&originalType=binary&ratio=1&rotation=0&showTitle=false&size=31089&status=done&style=none&taskId=ua1d9388f-7e35-427d-b266-1703c5007bc&title=&width=283.63635748871116)
#### ï¼ˆ2ï¼‰ç”¨ python ç¼–å†™ ID3 ç®—æ³•ã€‚
ä¹¦æ¥ä¸Šå›ï¼š
```python
class DTree:
    def __init__(self, epsilon=0.1):
        self.epsilon = epsilon
        self._tree = {}

    # ç†µ
    @staticmethod
    def calc_ent(datasets):
        data_length = len(datasets)
        label_count = {}
        for i in range(data_length):
            label = datasets[i][-1]
            if label not in label_count:
                label_count[label] = 0
            label_count[label] += 1
        ent = -sum([(p/data_length)*log(p/data_length, 2) for p in label_count.values()])
        return ent

    # ç»éªŒæ¡ä»¶ç†µ
    def cond_ent(self, datasets, axis=0):
        data_length = len(datasets)
        feature_sets = {}
        for i in range(data_length):
            feature = datasets[i][axis]
            if feature not in feature_sets:
                feature_sets[feature] = []
            feature_sets[feature].append(datasets[i])
        cond_ent = sum([(len(p)/data_length)*self.calc_ent(p) for p in feature_sets.values()])
        return cond_ent

    # ä¿¡æ¯å¢ç›Š
    @staticmethod
    def info_gain(ent, cond_ent):
        return ent - cond_ent

    def info_gain_train(self, datasets):
        count = len(datasets[0]) - 1
        ent = self.calc_ent(datasets)
        best_feature = []
        for c in range(count):
            c_info_gain = self.info_gain(ent, self.cond_ent(datasets, axis=c))
            best_feature.append((c, c_info_gain))
        # æ¯”è¾ƒå¤§å°
        best_ = max(best_feature, key=lambda x: x[-1])
        return best_

    def train(self, train_data):
        """
        input:æ•°æ®é›†D(DataFrameæ ¼å¼)ï¼Œç‰¹å¾é›†Aï¼Œé˜ˆå€¼eta
        output:å†³ç­–æ ‘T
        """
        _, y_train, features = train_data.iloc[:, :-1], train_data.iloc[:, -1], train_data.columns[:-1]
        # 1,è‹¥Dä¸­å®ä¾‹å±äºåŒä¸€ç±»Ckï¼Œåˆ™Tä¸ºå•èŠ‚ç‚¹æ ‘ï¼Œå¹¶å°†ç±»Ckä½œä¸ºç»“ç‚¹çš„ç±»æ ‡è®°ï¼Œè¿”å›T
        if len(y_train.value_counts()) == 1:
            return Node(root=True,
                        label=y_train.iloc[0])

        # 2, è‹¥Aä¸ºç©ºï¼Œåˆ™Tä¸ºå•èŠ‚ç‚¹æ ‘ï¼Œå°†Dä¸­å®ä¾‹æ ‘æœ€å¤§çš„ç±»Ckä½œä¸ºè¯¥èŠ‚ç‚¹çš„ç±»æ ‡è®°ï¼Œè¿”å›T
        if len(features) == 0:
            return Node(root=True, label=y_train.value_counts().sort_values(ascending=False).index[0])

        # 3,è®¡ç®—æœ€å¤§ä¿¡æ¯å¢ç›Š åŒ5.1,Agä¸ºä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾
        max_feature, max_info_gain = self.info_gain_train(np.array(train_data))
        max_feature_name = features[max_feature]

        # 4,Agçš„ä¿¡æ¯å¢ç›Šå°äºé˜ˆå€¼eta,åˆ™ç½®Tä¸ºå•èŠ‚ç‚¹æ ‘ï¼Œå¹¶å°†Dä¸­æ˜¯å®ä¾‹æ•°æœ€å¤§çš„ç±»Ckä½œä¸ºè¯¥èŠ‚ç‚¹çš„ç±»æ ‡è®°ï¼Œè¿”å›T
        if max_info_gain < self.epsilon:
            return Node(root=True, label=y_train.value_counts().sort_values(ascending=False).index[0])

        # 5,æ„å»ºAgå­é›†
        node_tree = Node(root=False, feature_name=max_feature_name, feature=max_feature)

        feature_list = train_data[max_feature_name].value_counts().index
        for f in feature_list:
            sub_train_df = train_data.loc[train_data[max_feature_name] == f].drop([max_feature_name], axis=1)

            # 6, é€’å½’ç”Ÿæˆæ ‘
            sub_tree = self.train(sub_train_df)
            node_tree.add_node(f, sub_tree)

        # pprint.pprint(node_tree.tree)
        return node_tree

    def fit(self, train_data):
        self._tree = self.train(train_data)
        return self._tree

    def predict(self, X_test):
        return self._tree.predict(X_test)

datasets, labels = create_data()
data_df = pd.DataFrame(datasets, columns=labels)
dt = DTree()
tree = dt.fit(data_df)
print(tree)

print(dt.predict(['è€å¹´', 'å¦', 'å¦', 'ä¸€èˆ¬']))

```
è¾“å‡ºç»“æœï¼š
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1669712673931-01fe4dc3-9a84-4708-92e8-0f37a1d9d189.png#averageHue=%230e0022&clientId=u1554ef67-f7a1-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=93&id=ud51320c2&margin=%5Bobject%20Object%5D&name=image.png&originHeight=205&originWidth=1124&originalType=binary&ratio=1&rotation=0&showTitle=false&size=24844&status=done&style=none&taskId=u6eaea2c1-7e4d-4ddf-b9c9-9a31c5b0704&title=&width=510.90907983543485)
### 2. ä½¿ç”¨ sklearn åº“ï¼Œå¯¹é¸¢å°¾èŠ±æ•°æ®å»ºç«‹å†³ç­–æ ‘ï¼Œå¹¶è¿›è¡Œå¯è§†åŒ–ã€‚
#### ï¼ˆ1ï¼‰scikit-learn å†³ç­–æ ‘ç®—æ³•ç±»åº“å†…éƒ¨å®ç°æ˜¯ä½¿ç”¨äº†è°ƒä¼˜è¿‡çš„ CART æ ‘ç®—æ³•ï¼Œæ—¢å¯ä»¥åšåˆ†ç±»ï¼Œåˆå¯ä»¥åšå›å½’ã€‚åˆ†ç±»å†³ç­–æ ‘çš„ç±»å¯¹åº”çš„æ˜¯ DecisionTreeClassifierï¼Œè€Œå›å½’å†³ç­–æ ‘çš„ç±»å¯¹åº”çš„æ˜¯ DecisionTreeRegressorã€‚ä¸¤è€…çš„å‚æ•°å®šä¹‰å‡ ä¹å®Œå…¨ç›¸åŒï¼Œä½†æ˜¯æ„ä¹‰ä¸å…¨ç›¸åŒã€‚åœ¨ [https://graphviz.org/download/](https://graphviz.org/download/) ä¸Šä¸‹è½½ graphviz,å®‰è£…æ—¶æ³¨æ„å‹¾é€‰åŠ ç¯å¢ƒå˜é‡ï¼Œåœ¨ anaconda prompt ä¸­ pip install graphviz ï¼Œå† pip install pydotplusã€‚
è¿™ä¸ªç•¥äº†ï¼Œå®‰è£…å°±å®Œäº‹å„¿äº†
#### ï¼ˆ2ï¼‰ä½¿ç”¨ DecisionTreeClassifier()æ„å»ºå†³ç­–æ ‘å¹¶è¿›è¡Œå¯è§†åŒ–ã€‚
åŒ…çš„è°ƒç”¨
```python
from sklearn.tree import DecisionTreeClassifier

from sklearn.tree import export_graphviz
import graphviz
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

from collections import Counter
import math
from math import log

import pprint

```

æ•°æ®é¢„å¤„ç†ï¼š
```python
# data
def create_data():
Â  Â  iris = load_iris()
Â  Â  df = pd.DataFrame(iris.data, columns=iris.feature_names)
Â  Â  df['label'] = iris.target
Â  Â  df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']
Â  Â  data = np.array(df.iloc[:100, [0, 1, -1]])
Â  Â  # print(data)
Â  Â  return data[:,:2], data[:,-1]


X, y = create_data()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
```
å†³ç­–æ ‘å¯è§†åŒ–ï¼š
```python
datasets, labels = create_data()
train_data = pd.DataFrame(datasets, columns=[0,1])

clf = DecisionTreeClassifier()
clf.fit(X_train, y_train,)
print(clf.score(X_test, y_test))
tree_pic = export_graphviz(clf, out_file="mytree.pdf")
with open('mytree.pdf') as f:
    dot_graph = f.read()
graphviz.Source(dot_graph)
```
è¾“å‡ºç»“æœæ˜¾ç¤ºï¼š
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1669713848073-3fe3aa92-ab1a-4053-bc22-f17784ce9bf9.png#averageHue=%23100224&clientId=u1554ef67-f7a1-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=16&id=uc9e71f0d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=35&originWidth=336&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2362&status=done&style=none&taskId=u3e6a5db2-6b8a-4a21-8035-f1b432d6619&title=&width=152.72726941699833)
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1669713827478-3163388f-ef96-47d8-8b88-3c39964b422d.png#averageHue=%230e0022&clientId=u1554ef67-f7a1-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=310&id=ue9984adf&margin=%5Bobject%20Object%5D&name=image.png&originHeight=682&originWidth=1121&originalType=binary&ratio=1&rotation=0&showTitle=false&size=102969&status=done&style=none&taskId=ue4168c02-c206-431a-a62b-7f4c4ea7f25&title=&width=509.5454435013545)

### 3. åœ¨é¸¢å°¾èŠ±æ•°æ®é›†ä¸Šä½¿ç”¨éšæœºæ£®æ—è¿›è¡Œåˆ†ç±»ï¼Œæœ‰æ¡ä»¶çš„å¯è¿›è¡Œå¯è§†åŒ–ã€‚
```python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
import matplotlib as mpl
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
 
mpl.rcParams['font.sans-serif'] = ['SimHei']
mpl.rcParams['axes.unicode_minus'] = False
RF = RandomForestClassifier(n_estimators=100, n_jobs=4, oob_score=True)
iris = load_iris()
X1 = iris.data
y = iris.target
X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.25, random_state=0)
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
# classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)
RF.fit(X_train, y_train)
y_pred = RF.predict(X_test)
print("éšæœºæ£®æ—å‡†ç¡®ç‡:", accuracy_score(y_test, y_pred))
print("å…¶ä»–è¯„ä¼°æŒ‡æ ‡ï¼š\n", classification_report(y_test, y_pred, target_names=['0', '1', '2']))

```
è¾“å‡ºç»“æœï¼š
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1669714005610-d9b9c262-0f05-40a9-8792-18ea973acced.png#averageHue=%230e0021&clientId=u1554ef67-f7a1-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=179&id=u60861647&margin=%5Bobject%20Object%5D&name=image.png&originHeight=393&originWidth=960&originalType=binary&ratio=1&rotation=0&showTitle=false&size=43071&status=done&style=none&taskId=u6baaecd3-17f5-405b-a825-e9652e80633&title=&width=436.36362690570945)
```python
# ç”»å›¾
x = iris.data[:, :2]
RF.fit(x, y)
N = 50
cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])
cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])
# for weight in ['uniform', 'distance']:
x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1
y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1
xx, yy = np.meshgrid(np.linspace(x_min, x_max, N), np.linspace(y_min, y_max, N))
z_show = np.stack((xx.flat, yy.flat), axis=1) Â # æµ‹è¯•ç‚¹
# z = RF.predict(np.c_[xx.ravel(), yy.ravel()])
z = RF.predict(z_show)
plt.figure()
plt.pcolormesh(xx, yy, z.reshape(xx.shape), shading='auto', cmap=cmap_light)
plt.scatter(x[:, 0], x[:, 1], c=y, cmap=cmap_bold, edgecolors='k', s=20)
plt.xlim(xx.min(), xx.max())
plt.title('RandomForestClassifier')
plt.show()
# print('RandomForestClassifier:', RF.score(x, y))
```
è¾“å‡ºå›¾åƒï¼š
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1669713982282-738c1ab0-056a-49ed-973c-c9039c690382.png#averageHue=%23d0a159&clientId=u1554ef67-f7a1-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=491&id=u99375304&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1081&originWidth=1258&originalType=binary&ratio=1&rotation=0&showTitle=false&size=62162&status=done&style=none&taskId=u3d5ba88e-a875-4ea0-9067-2de2ad44586&title=&width=571.8181694243568)

##  å››ã€å®éªŒå®‰å…¨äº‹é¡¹ 
å®éªŒè¿‡ç¨‹ä¸­æ³¨æ„ç”¨ç”µå®‰å…¨ã€‚
##  äº”ã€å®éªŒæäº¤æ–¹å¼
 âˆš å®éªŒæŠ¥å‘Š â–¡ ç°åœºæ‰“åˆ† â–¡ çº¿ä¸Šå¹³å°æäº¤  

# å®éªŒå›› æ”¯æŒå‘é‡æœº
## ä¸€ã€å®éªŒç›®çš„

### 1. æŒæ¡çº¿æ€§å¯åˆ†æ”¯æŒå‘é‡æœºçš„åŸç†åŠå®ç°ã€‚
### 2. æŒæ¡ sklearn åº“ä¸­æ”¯æŒå‘é‡æœºçš„å®ç°æ–¹æ³•ã€‚
## äºŒã€å®éªŒåŸç†åŠè¯´æ˜
æ”¯æŒå‘é‡æœºæœ€ç®€å•çš„æƒ…å†µæ˜¯çº¿æ€§å¯åˆ†æ”¯æŒå‘é‡æœºï¼Œæˆ–ç¡¬é—´éš”æ”¯æŒå‘é‡æœºã€‚æ„å»ºå®ƒçš„æ¡ä»¶æ˜¯è®­ç»ƒæ•°æ®çº¿æ€§å¯åˆ†ã€‚å…¶å­¦ä¹ ç­–ç•¥æ˜¯æœ€å¤§é—´éš”æ³•ã€‚å¯ä»¥è¡¨ç¤ºä¸ºå‡¸äºŒæ¬¡è§„åˆ’é—®é¢˜ï¼Œå…¶åŸå§‹æœ€ä¼˜åŒ–é—®é¢˜ä¸º
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1668350828142-d8440d02-430f-496f-b2da-666d4abf33e3.png#averageHue=%23f9f9f9&clientId=u385df243-09b6-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=80&id=ue7373b88&margin=%5Bobject%20Object%5D&name=image.png&originHeight=177&originWidth=786&originalType=binary&ratio=1&rotation=0&showTitle=false&size=22082&status=done&style=none&taskId=u7a06dfb1-e590-4a14-b3c0-762d8445480&title=&width=357.2727195290496)
 æ±‚å¾—æœ€ä¼˜åŒ–é—®é¢˜çš„è§£ä¸º wâˆ— ï¼Œğ‘ğ‘âˆ— ï¼Œå¾—åˆ°çº¿æ€§å¯åˆ†æ”¯æŒå‘é‡æœºï¼Œåˆ†ç¦»è¶…å¹³é¢æ˜¯  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1668350846487-9845d5ce-83a9-44f5-a93f-20897d2d47ba.png#averageHue=%23f4f4f4&clientId=u385df243-09b6-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=26&id=ueaae46b9&margin=%5Bobject%20Object%5D&name=image.png&originHeight=58&originWidth=272&originalType=binary&ratio=1&rotation=0&showTitle=false&size=5537&status=done&style=none&taskId=uce7d6a5c-fcc5-4d6c-97bc-07d68c323b6&title=&width=123.63636095661768)
åˆ†ç±»å†³ç­–å‡½æ•°æ˜¯  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1668350897772-6b5925d6-b995-4698-ac3c-7a2ba91a36ff.png#averageHue=%23f3f3f3&clientId=u385df243-09b6-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=35&id=u3cfb874d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=76&originWidth=371&originalType=binary&ratio=1&rotation=0&showTitle=false&size=10870&status=done&style=none&taskId=ua3e5b529-a82e-4cd1-bd06-b76801f6d0a&title=&width=168.63635998126898)
 æœ€å¤§é—´éš”æ³•ä¸­ï¼Œå‡½æ•°é—´éš”ä¸å‡ ä½•é—´éš”æ˜¯é‡è¦çš„æ¦‚å¿µã€‚ çº¿æ€§å¯åˆ†æ”¯æŒå‘é‡æœºçš„æœ€ä¼˜è§£å­˜åœ¨ä¸”å”¯ä¸€ã€‚ä½äºé—´éš”è¾¹ç•Œä¸Šçš„å®ä¾‹ç‚¹ä¸ºæ”¯æŒå‘é‡ã€‚æœ€ä¼˜ åˆ†ç¦»è¶…å¹³é¢ç”±æ”¯æŒå‘é‡å®Œå…¨å†³å®šã€‚ äºŒæ¬¡è§„åˆ’é—®é¢˜çš„å¯¹å¶é—®é¢˜æ˜¯  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/32555890/1668350922375-fb6e08a6-9501-428a-b8e7-784a2b83e6f0.png#averageHue=%23f6f6f6&clientId=u385df243-09b6-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=133&id=u96ce10bd&margin=%5Bobject%20Object%5D&name=image.png&originHeight=293&originWidth=582&originalType=binary&ratio=1&rotation=0&showTitle=false&size=39573&status=done&style=none&taskId=u55f9ccbd-267f-4441-985c-7764753d1d9&title=&width=264.54544881158637)
 é€šå¸¸ï¼Œé€šè¿‡æ±‚è§£å¯¹å¶é—®é¢˜å­¦ä¹ çº¿æ€§å¯åˆ†æ”¯æŒå‘é‡æœºï¼Œå³é¦–å…ˆæ±‚è§£å¯¹å¶é—®é¢˜çš„æœ€ä¼˜å€¼ ğ‘âˆ— ï¼Œç„¶åæ±‚æœ€ä¼˜å€¼ğ‘¤âˆ— å’Œğ‘âˆ— ï¼Œå¾—å‡ºåˆ†ç¦»è¶…å¹³é¢å’Œåˆ†ç±»å†³ç­–å‡½æ•°ã€‚  
##  ä¸‰ã€å®éªŒå†…å®¹  
###  1ï¼ä½¿ç”¨ sklearn åº“ï¼Œä½¿ç”¨é¸¢å°¾èŠ±æ•°æ®é›†ï¼Œå¯¹é¸¢å°¾èŠ±è¿›è¡Œåˆ†ç±»ã€‚ 
ï¼ˆ1ï¼‰æ•°æ®å‡†å¤‡ï¼Œè½½å…¥æ•°æ®é›†ï¼Œå¹¶è¿›è¡Œæ•°æ®é›†åˆ†å‰²ï¼› 
ï¼ˆ2ï¼‰æ¨¡å‹æ­å»ºï¼›
ï¼ˆ3ï¼‰æ¨¡å‹è®­ç»ƒï¼› 
ï¼ˆ4ï¼‰æ¨¡å‹è¯„ä¼°ï¼› 
ï¼ˆ5ï¼‰å¯è§†åŒ–ã€‚ 
### 2. å®Œæˆä¹ é¢˜ 7.2ï¼Œç¼–ç¨‹å®ç°ã€‚
##  å››ã€å®éªŒå®‰å…¨äº‹é¡¹ 
å®éªŒè¿‡ç¨‹ä¸­æ³¨æ„ç”¨ç”µå®‰å…¨ã€‚ 
## äº”ã€å®éªŒæäº¤æ–¹å¼ 
âˆš å®éªŒæŠ¥å‘Š â–¡ ç°åœºæ‰“åˆ† â–¡ çº¿ä¸Šå¹³å°æäº¤  
